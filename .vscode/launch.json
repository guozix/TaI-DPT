{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": 
                    
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP_dense",  // ZeroshotCLIP 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",  //  voc2007_partial voc2012_distill_3  coco2014_distill   nuswide_distill
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__oxford_flowers/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]

                // origin coop
                // [
                //     "--root", "/home/weiyuxiang/gzx/CoOp-main/coop_datasets",
                //     "--seed", "3",
                //     "--trainer", "CoOp", 
                //     "--dataset-config-file", "configs/datasets/oxford_flowers.yaml",
                //     "--config-file", "configs/trainers/CoOp/rn50.yaml",
                //     "--output-dir", "output/__debug__oxford_flowers/CoOp/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.COOP.N_CTX", "16",
                //     "TRAINER.COOP.CSC", "False",
                //     "TRAINER.COOP.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16"
                // ]
                
                // ############### baseline test #############
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP_dense", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",  // voc2007_distill  nuswide_distill  coco2014_distill
                //     "--config-file", "configs/trainers/Caption_distill_double/rn50_fixscale.yaml",
                //     "--output-dir", "output/__debug__/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]

                
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_2.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]

                
                // COCO2014
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__coco/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]


                // CIFAR10
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP", 
                //     "--dataset-config-file", "configs/datasets/cifar10_distill.yaml",
                //     "--config-file", "configs/trainers/CoOp/rn50.yaml",
                //     "--output-dir", "output/__debug__cifar/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]

                // NUS-WIDE
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--trainer", "ZeroshotCLIP", 
                //     "--dataset-config-file", "configs/datasets/nuswide_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__nuswide/ZeroshotCLIP/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]



                // dual
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     "--trainer", "ZeroshotCLIP_dual",  // ZeroshotCLIP_dual
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__/ZeroshotCLIP_dual/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only"
                // ]


                // testset
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption", 
                //     "--dataset-config-file", "configs/datasets/voc2012_testset.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16"
                // ]

                // trainset
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset_gt.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_/Caption/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "0"
                // ]

                // trainset eval only
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     // "--seed", "3",
                //     "--trainer", "Caption", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_/CoOp/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_trainset_sigmoid_median_new_lr0.0001/Caption/rn50/nctx16_cscFalse_ctpend/seed1", // output/voc2012_caption_trainset/Caption/rn50/nctx16_cscFalse_ctpend/seed1  output/voc2012_caption_trainset/Caption/rn50/nctx16_cscTrue_ctpend/seed1
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]

                // // trainset GT eval only
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     // "--seed", "3",
                //     "--trainer", "Caption", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset_gt.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc__/CoOp/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_trainset_gt/Caption/rn50/nctx16_cscFalse_ctpend/seed1", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]



                // norm BCE eval only
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     // "--seed", "3",
                //     "--trainer", "Caption", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__oxford_flowers/CoOp/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_trainset_gt_logscale50_norm_BCE/Caption/rn50/nctx16_cscFalse_ctpend/seed1",
                //     "--load-epoch", "20",
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]

                // // // trainset  caption_query
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption_query", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption_query/rn50.yaml",
                //     "--output-dir", "output/__debug_caption_query/Caption_query/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "32",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "1000"
                // ]

                // // trainset caption_query eval only
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     // "--seed", "3",
                //     "--trainer", "Caption_query", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption/rn50.yaml",
                //     "--output-dir", "output/__debug__/CoOp/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_trainset_gt_query_BCE/Caption_query/rn50/nctx32_cscFalse_ctpend/seed1",
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "32",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]


                // // trainset caption_distill
                // [
                //     "--root", "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__/Caption_distill/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "32",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]



                // // trainset unify
                // [
                //     "--root", "/home/qiangwenjie/datasets",  // "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_unify", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_unify/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_Caption_distill_unify_dense/Caption/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "0"
                // ]


                // // debug dense unify
                // [
                //     "--root", "/home/qiangwenjie/datasets",  // "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_unify", 
                //     "--dataset-config-file", "configs/datasets/voc2012_trainset_gt.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_unify/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_Caption_distill_unify_dense/Caption/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "0"
                // ]

                // // debug dense unify distill
                // [
                //     "--root", "/home/qiangwenjie/datasets",  // "/home/weiyuxiang/gzx/VOS/datas",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_2.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_Caption_distill/Caption/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "1500"
                // ]



                // distill ===========================================================================================================

                // // // debug distill
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_2.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     // "--model-dir", "output/voc2012_caption_distill_new_data_b512_CE_try_valid_seed123_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3",  // voc2012_caption_distill_new_data_b512_CE_try8  voc2012_caption_distill_new_data_b512_CE_try9_valid_CE  voc2012_caption_distill_new_data_b512_CE_try7_BCE_singleP  voc2012_caption_distill_new_data_b512_CE_try8_BCE_singleP
                //     "--model-dir", "output_pre/voc2012_caption_trainset_gt/Caption/rn50/nctx16_cscFalse_ctpend/seed1",
                //     "--eval-only", 
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS","16",
                //     "DATASET.SAMPLE", "2000"
                // ]

                // debug distill dual
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     // "--seed", "3",
                //     "--trainer", "Caption_distill_dual", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_2.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_dual/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_dual/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir",  "output/voc2012_caption_distill_dual_new_data_b512_freezeP_ft_w_BCE/Caption_distill_dual/rn50/nctx16_cscFalse_ctpend/seed1", // "output/voc2012_caption_distill_dual_new_data_b512_freezeP_ft/Caption_distill_dual/rn50/nctx16_cscFalse_ctpend/seed1", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]


                // baseline dualp
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     // "--seed", "3",
                //     "--trainer", "Caption_dual", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_2.yaml",
                //     "--config-file", "configs/trainers/Caption_dual/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill/Caption_dual/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_trainset_dualp_BCE_scale100/Caption_dual/rn50/nctx16_cscFalse_ctpend/seed1", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                // ]


                // // debug distill gt
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_gt_caption_test.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_distill_new_data_b512_CE_try_valid_seed123_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3",  // voc2012_caption_distill_new_data_b512_CE_try8  voc2012_caption_distill_new_data_b512_CE_try9_valid_CE  voc2012_caption_distill_new_data_b512_CE_try7_BCE_singleP  voc2012_caption_distill_new_data_b512_CE_try8_BCE_singleP
                //     // "--model-dir", "output_pre/voc2012_caption_trainset_gt/Caption/rn50/nctx16_cscFalse_ctpend/seed1",
                //     "--eval-only", 
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS","16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // eval distill ranking loss
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     // "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_3.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_CE_try_valid_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL_traintemp4/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3",
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "1500"
                // ]

                // eval distill ranking loss  GCN
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     // "--seed", "3",
                //     "--trainer", "Caption_distill_gcn", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_3.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_gcn/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_gcn/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/voc2012_caption_distill_3_v2_RL_t4_GCN_init/Caption_distill_gcn/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_CE_try_valid_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL_traintemp5/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2",
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "1500"
                // ]

                
                // distill ranking loss  coco2014
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_coco/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/coco2014_caption_distill_RL_2/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // distill ranking loss  GCN  coco
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_gcn", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_gcn/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_gcn_coco/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_CE_try_valid_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL_traintemp5/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2",
                //     // "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // distill ranking loss  GCN  coco  eval
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_gcn", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_gcn/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_gcn_coco/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/coco2014_caption_distill_RL_t4_GCN_2layer_eye/Caption_distill_gcn/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // dual gcn
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_dual_gcn", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_3.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_dual_gcn/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_Caption_distill_dual_gcn/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_CE_try_valid_t70/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed3", 
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_RL_traintemp5/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed2",
                //     // "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]

                                
                // distill ranking loss  NUSWIDE
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill", 
                //     "--dataset-config-file", "configs/datasets/nuswide_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill/rn50.yaml",
                //     "--output-dir", "output/__debug__ml_voc_caption_distill_nuswide_distill/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/nuswide_distill_RL/Caption_distill/rn50/nctx16_cscFalse_ctpend/seed1", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // // distill dense unify  eval
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_double", 
                //     "--dataset-config-file", "configs/datasets/voc2012_distill_3.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_double/rn50.yaml",
                //     "--output-dir", "output/__debug__voc2012_caption_distill_3_v2_b512_dense_RL_traintemp4_3_5/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed2",
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_dense_RL_traintemp4_3_5/Caption_distill_double/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]


                // // dualcoop
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_dual", 
                //     "--dataset-config-file", "configs/datasets/voc2007_partial.yaml",
                //     "--config-file", "configs/trainers/Caption_dual/rn50.yaml",
                //     "--output-dir", "output/__debug__dualcoop/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed2",
                //     // "--model-dir", "output/voc2012_caption_distill_3_v2_b512_dense_RL_traintemp4_3_5/Caption_distill_double/rn50/nctx16_cscFalse_ctpend/seed2", 
                //     // "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "2000"
                // ]

                // dualcoop eval
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_dual", 
                //     // "--dataset-config-file", "configs/datasets/voc2007_partial.yaml",
                //     "--dataset-config-file", "configs/datasets/coco2014_partial.yaml",
                //     "--config-file", "configs/trainers/Caption_dual/rn101.yaml",
                //     "--output-dir", "output/__debug__dualcoop_aug2/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed2",
                //     // "--model-dir", "output/voc2007_partial_dualcoop_haug2_spatial20_448_CSC/Caption_dual/rn101/nctx16_cscTrue_ctpend/seed1", 
                //     "--model-dir", "output_pre_paper/coco2014_partial_dualcoop_haug2_spatial20_448_CSC_p0_5_b64/Caption_dual/rn101/nctx16_cscTrue_ctpend/seed1",
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "True",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "16",
                //     "DATASET.SAMPLE", "0"
                // ]


                // fewshot
                [
                    "--root", "/home/qiangwenjie/datasets",
                    "--seed", "0",
                    "--trainer", "Caption_distill_support", 
                    // "--dataset-config-file", "configs/datasets/voc2007_fewshot.yaml",
                    "--dataset-config-file", "configs/datasets/coco2014_fewshot.yaml",
                    "--config-file", "configs/trainers/Caption_distill_support/rn50.yaml",
                    "--output-dir", "output/__debug__fewshot_voc/Caption/rn50_16shots/nctx16_cscFalse_ctpend/seed2",
                    // "--model-dir", "output/voc2007_fewshot/Caption_distill_support/rn50/nctx16_cscFalse_ctpend/seed0/", 
                    "--model-dir", "output_pre_paper/coco2014_fewshot_shot1_person/Caption_distill_support/rn50/nctx16_cscFalse_ctpend/seed0", 
                    "--eval-only",
                    "TRAINER.Caption.N_CTX", "16",
                    "TRAINER.Caption.CSC", "False",
                    "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                    "DATASET.NUM_SHOTS", "4",
                    "DATASET.SAMPLE", "0"
                ]

                
                // double COCO eval
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "3",
                //     "--trainer", "Caption_distill_double", 
                //     "--dataset-config-file", "configs/datasets/coco2014_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_double/rn50_coco2014.yaml",
                //     "--output-dir", "output/__debug__coco2014_caption_distill_double/Caption_distill_double/rn50_16shots/nctx16_cscFalse_ctpend/seed3",
                //     "--model-dir", "output/coco2014_caption_distill_v4_nofeatcap/Caption_distill_double/rn50_coco2014/nctx16_cscFalse_ctpend/seed3", 
                    
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "5",
                //     "DATASET.SAMPLE", "0"
                // ]

                // double VOC eval
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "1",
                //     "--trainer", "Caption_distill_double",
                //     "--dataset-config-file", "configs/datasets/voc2007_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_double/rn50_fixscale.yaml",
                //     "--output-dir", "output/__vis__VOC2007_caption_distill_double/Caption_distill_double/rn50_16shots/nctx16_cscFalse_ctpend/seed1",
                //     // "--model-dir", "output/voc2007_caption_distill_abinf/Caption_distill_double/rn50_fixscale/nctx16_cscFalse_ctpend/seed3", 
                //     // "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "5",
                //     "DATASET.SAMPLE", "0"
                // ]



                // double NUS
                // [
                //     "--root", "/home/qiangwenjie/datasets",
                //     "--seed", "1",
                //     "--trainer", "Caption_distill_double",
                //     "--dataset-config-file", "configs/datasets/nuswide_distill.yaml",
                //     "--config-file", "configs/trainers/Caption_distill_double/rn50_nuswide.yaml",
                //     "--output-dir", "output/__debug__NUS_caption_distill_double/Caption_distill_double/rn50_16shots/nctx16_cscFalse_ctpend/seed2",
                //     "--model-dir", "output/nuswide_distill_v3_limit_RL_fixscale/Caption_distill_double/rn50_fixscale/nctx16_cscFalse_ctpend/seed1", 
                //     "--eval-only",
                //     "TRAINER.Caption.N_CTX", "16",
                //     "TRAINER.Caption.CSC", "False",
                //     "TRAINER.Caption.CLASS_TOKEN_POSITION", "end",
                //     "DATASET.NUM_SHOTS", "5",
                //     "DATASET.SAMPLE", "0"
                // ]
        }
    ]
}
